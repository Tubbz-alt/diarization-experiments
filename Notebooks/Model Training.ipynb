{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(M=5, N=4, beta1=0.5, beta2=0.9, comment='', hidden=768, hop=0.01, iteration=100000, loss='softmax', lr=0.001, max_batch_utterances=1000, model_num=6, model_path='./tisv_model', nfft=512, noise_filenum=16, noise_path='/datadrive2/dalon/diarization-experiments/Speaker_Verification/data/VCTK-Corpus/noise', num_layer=3, optim='sgd', proj=256, restore=False, sr=16000, tdsv=False, tdsv_frame=160, test_path='/datadrive2/dalon/diarization-experiments/Speaker_Verification/data/VCTK-Corpus/test', tisv_frame=160, tisv_frame_min=50, train=False, train_path='/datadrive2/dalon/diarization-experiments/Speaker_Verification/data/VCTK-Corpus/train', window=0.025)\n",
      "Log path: /datadrive/dalon/diarization-experiments/Notebooks/model-training.logs\n"
     ]
    }
   ],
   "source": [
    "import os, logging\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from configuration import get_config\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "config = get_config()\n",
    "log_file = os.path.abspath(\"model-training.logs\")\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\"\n",
    "    )\n",
    "print(f'Log path: {log_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/datadrive/dalon/models/m-50-20-512-128\" # model save path\n",
    "config.train_path = \"/datadrive/dalon/diarizer-dataset/vctk-vox1n2-libri-npy\"\n",
    "config.N = 50 # Number of speakers per batch\n",
    "config.M = 20 # Number of utterences per speaker\n",
    "config.iteration = 50000000 # Number of iterations to run\n",
    "config.lr = 1e-3\n",
    "config.hidden = 512 # hidden state dimension of lstm\n",
    "config.proj = 128 # projection dimension of lstm\n",
    "logging.info(f'N={config.N}, M={config.M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalVar(object):\n",
    "    epoch = 0\n",
    "    dataset_size = 0\n",
    "    start =  0\n",
    "    dataset_file_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_batch(speaker_num=config.N, utter_num=config.M, shuffle=True, noise_filenum=None, utter_start=0):\n",
    "    \"\"\" Generate 1 batch.\n",
    "        shuffle : random sampling or not\n",
    "    :return: 1 random numpy batch (frames x batch(NM) x n_mels)\n",
    "    \"\"\"\n",
    "#     print(f'In random')\n",
    "#     print(f'Epoch: {epoch}, start: {start}')\n",
    "    path = config.train_path\n",
    "    if GlobalVar.dataset_size == 0:\n",
    "        GlobalVar.dataset_file_list = os.listdir(path)\n",
    "        random.shuffle(GlobalVar.dataset_file_list)\n",
    "        GlobalVar.dataset_size = len(GlobalVar.dataset_file_list)\n",
    "\n",
    "    selected_files = GlobalVar.dataset_file_list[GlobalVar.start:GlobalVar.start+speaker_num]\n",
    "    GlobalVar.start += speaker_num\n",
    "    if GlobalVar.start + speaker_num >= GlobalVar.dataset_size:\n",
    "        logging.info(f'Epoch {GlobalVar.epoch} completed at {str(datetime.utcnow().isoformat()[:-3])}!')\n",
    "        GlobalVar.epoch += 1\n",
    "        GlobalVar.start = 0\n",
    "#         GlobalVar.dataset_file_list = random.sample(os.listdir(path), GlobalVar.dataset_size)\n",
    "        random.shuffle(GlobalVar.dataset_file_list)\n",
    "#     if shuffle:\n",
    "#         selected_files = random.sample(np_file_list, speaker_num)  # select random N speakers (default N=4)\n",
    "#     else:\n",
    "#         selected_files = np_file_list[:speaker_num]                # select first N speakers\n",
    "\n",
    "    utter_batch = []\n",
    "    for file in selected_files:\n",
    "#         print(file)\n",
    "        utters = np.load(os.path.join(path, file))        # load utterance spectrogram of selected speaker\n",
    "        if shuffle:\n",
    "            utter_index = np.random.randint(0, utters.shape[0], utter_num)   # select M utterances per speaker (default M=5)\n",
    "            utter_batch.append(utters[utter_index])       # each speakers utterance [M, n_mels, frames] is appended\n",
    "        else:\n",
    "            utter_batch.append(utters[utter_start: utter_start+utter_num])\n",
    "\n",
    "    utter_batch = np.concatenate(utter_batch, axis=0)     # utterance batch [batch(NM), n_mels, frames]\n",
    "\n",
    "    # for train session, random slicing of input batch\n",
    "    # to confirm with \"d-vector V3\" we pick ranfom slice\n",
    "    frame_slice = np.random.randint(config.tisv_frame_min, config.tisv_frame)\n",
    "    utter_batch = utter_batch[:,:,:frame_slice]\n",
    "\n",
    "    utter_batch = np.transpose(utter_batch, axes=(2,0,1))     # transpose [frames, batch, n_mels]\n",
    "\n",
    "    return utter_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(embedded, w, b, N=config.N, M=config.M, P=config.proj, center=None):\n",
    "    \"\"\" Calculate similarity matrix from embedded utterance batch (NM x embed_dim) eq. (9)\n",
    "        Input center to test enrollment. (embedded for verification)\n",
    "    :return: tf similarity matrix (NM x N)\n",
    "    \"\"\"\n",
    "    embedded_split = tf.reshape(embedded, shape=[N, M, P])\n",
    "\n",
    "    if center is None:\n",
    "        center = normalize(tf.reduce_mean(embedded_split, axis=1))              # [N,P] normalized center vectors eq.(1)\n",
    "        center_except = normalize(tf.reshape(tf.reduce_sum(embedded_split, axis=1, keep_dims=True)\n",
    "                                             - embedded_split, shape=[N*M,P]))  # [NM,P] center vectors eq.(8)\n",
    "        # make similarity matrix eq.(9)\n",
    "        S = tf.concat(\n",
    "            [tf.concat([tf.reduce_sum(center_except[i*M:(i+1)*M,:]*embedded_split[j,:,:], axis=1, keep_dims=True) if i==j\n",
    "                        else tf.reduce_sum(center[i:(i+1),:]*embedded_split[j,:,:], axis=1, keep_dims=True) for i in range(N)],\n",
    "                       axis=1) for j in range(N)], axis=0)\n",
    "    else :\n",
    "        # If center(enrollment) exist, use it.\n",
    "        S = tf.concat(\n",
    "            [tf.concat([tf.reduce_sum(center[i:(i + 1), :] * embedded_split[j, :, :], axis=1, keep_dims=True) for i\n",
    "                        in range(N)],\n",
    "                       axis=1) for j in range(N)], axis=0)\n",
    "\n",
    "    S = tf.abs(w)*S+b   # rescaling\n",
    "\n",
    "    return S\n",
    "\n",
    "def loss_cal(S, type=\"softmax\", N=config.N, M=config.M):\n",
    "    \"\"\" calculate loss with similarity matrix(S) eq.(6) (7) \n",
    "    :type: \"softmax\" or \"contrast\"\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    S_correct = tf.concat([S[i*M:(i+1)*M, i:(i+1)] for i in range(N)], axis=0)  # colored entries in Fig.1\n",
    "\n",
    "    if type == \"softmax\":\n",
    "        total = -tf.reduce_sum(S_correct-tf.log(tf.reduce_sum(tf.exp(S), axis=1, keep_dims=True) + 1e-6))\n",
    "    elif type == \"contrast\":\n",
    "        S_sig = tf.sigmoid(S)\n",
    "        S_sig = tf.concat([tf.concat([0*S_sig[i*M:(i+1)*M, j:(j+1)] if i==j\n",
    "                              else S_sig[i*M:(i+1)*M, j:(j+1)] for j in range(N)], axis=1)\n",
    "                             for i in range(N)], axis=0)\n",
    "        total = tf.reduce_sum(1-tf.sigmoid(S_correct)+tf.reduce_max(S_sig, axis=1, keep_dims=True))\n",
    "    else:\n",
    "        raise AssertionError(\"loss type should be softmax or contrast !\")\n",
    "\n",
    "    return total\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\" normalize the last dimension vector of the input matrix\n",
    "    :return: normalized input\n",
    "    \"\"\"\n",
    "    return x/tf.sqrt(tf.reduce_sum(x**2, axis=-1, keep_dims=True)+1e-6)\n",
    "\n",
    "def optim(lr):\n",
    "    \"\"\" return optimizer determined by configuration\n",
    "    :return: tf optimizer\n",
    "    \"\"\"\n",
    "    if config.optim == \"sgd\":\n",
    "        return tf.train.GradientDescentOptimizer(lr)\n",
    "    elif config.optim == \"rmsprop\":\n",
    "        return tf.train.RMSPropOptimizer(lr)\n",
    "    elif config.optim == \"adam\":\n",
    "        return tf.train.AdamOptimizer(lr, beta1=config.beta1, beta2=config.beta2)\n",
    "    else:\n",
    "        raise AssertionError(\"Wrong optimizer type!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model init done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-299d716d8f8b>:52: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.reset_default_graph()    # reset graph\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    # draw graph\n",
    "    batch = tf.placeholder(shape= [None, config.N*config.M, 40], dtype=tf.float32)  # input batch (time x batch x n_mel)\n",
    "    lr = tf.placeholder(dtype= tf.float32)  # learning rate\n",
    "#     global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    w = tf.get_variable(\"w\", initializer= np.array([10], dtype=np.float32))\n",
    "    b = tf.get_variable(\"b\", initializer= np.array([-5], dtype=np.float32))\n",
    "\n",
    "    # embedding lstm (3-layer default)\n",
    "    with tf.variable_scope(\"lstm\"):\n",
    "        lstm_cells = [tf.contrib.rnn.LSTMCell(num_units=config.hidden, num_proj=config.proj) for i in range(config.num_layer)]\n",
    "        lstm = tf.contrib.rnn.MultiRNNCell(lstm_cells)    # define lstm op and variables\n",
    "        outputs, _ = tf.nn.dynamic_rnn(cell=lstm, inputs=batch, dtype=tf.float32, time_major=True)   # for TI-VS must use dynamic rnn\n",
    "        embedded = outputs[-1]                            # the last ouput is the embedded d-vector\n",
    "        embedded = normalize(embedded)                    # normalize\n",
    "    logging.info(f'embedded size: {embedded.shape}')\n",
    "\n",
    "    # loss\n",
    "    sim_matrix = similarity(embedded, w, b)\n",
    "    logging.info(f\"similarity matrix size: {sim_matrix.shape}\")\n",
    "    loss = loss_cal(sim_matrix, type=config.loss)\n",
    "\n",
    "    # optimizer operation\n",
    "    trainable_vars= tf.trainable_variables()                # get variable list\n",
    "    optimizer= optim(lr)                                    # get optimizer (type is determined by configuration)\n",
    "    grads, vars= zip(*optimizer.compute_gradients(loss))    # compute gradients of variables with respect to loss\n",
    "    grads_clip, _ = tf.clip_by_global_norm(grads, 3.0)      # l2 norm clipping by 3\n",
    "    grads_rescale= [0.01*grad for grad in grads_clip[:2]] + grads_clip[2:]   # smaller gradient scale for w, b\n",
    "    train_op= optimizer.apply_gradients(zip(grads_rescale, vars), global_step= global_step)   # gradient update operation\n",
    "\n",
    "    # check variables memory\n",
    "    variable_count = np.sum(np.array([np.prod(np.array(v.get_shape().as_list())) for v in trainable_vars]))\n",
    "    logging.info(f\"total variables : {variable_count}\")\n",
    "\n",
    "# record loss\n",
    "loss_summary = tf.summary.scalar(\"loss\", loss)\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver(max_to_keep=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/datadrive/dalon/models/m-50-20-512-128/./Check_Point/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:/datadrive/dalon/models/m-50-20-512-128/./Check_Point/model.ckpt-1 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ac3ebb0a168b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# run forward and backward propagation and update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             _, loss_cur, summary = sess.run([train_op, loss, merged],\n\u001b[0;32m---> 24\u001b[0;31m                                   feed_dict={batch: random_batch(), lr: config.lr*lr_factor})\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_cur\u001b[0m    \u001b[0;31m# accumulated loss for each 100 iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-170352b5e7a0>\u001b[0m in \u001b[0;36mrandom_batch\u001b[0;34m(speaker_num, utter_num, shuffle, noise_filenum, utter_start)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#         print(file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mutters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# load utterance spectrogram of selected speaker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mutter_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutter_num\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# select M utterances per speaker (default M=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datadrive/miniconda3/envs/diarizer/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 433\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datadrive/miniconda3/envs/diarizer/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # %%time\n",
    "\n",
    "    #___________Debug________________\n",
    "    # config.iteration = 100000\n",
    "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "    logging.info(f'Training started at: {str(datetime.utcnow().isoformat()[:-3])}')\n",
    "    config_tensorflow = tf.ConfigProto()\n",
    "    config_tensorflow.gpu_options.allow_growth = True\n",
    "\n",
    "    # training session\n",
    "    with tf.Session(config=config_tensorflow) as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        os.makedirs(os.path.join(path, \"Check_Point\"))#, exist_ok=True)  # make folder to save model\n",
    "        os.makedirs(os.path.join(path, \"logs\"), exist_ok=True)          # make folder to save log\n",
    "        writer = tf.summary.FileWriter(os.path.join(path, \"logs\"), sess.graph)\n",
    "        epoch = 0\n",
    "        lr_factor = 1   # lr decay factor ( 1/2 per 10000 iteration)\n",
    "        loss_acc = 0    # accumulated loss ( for running average of loss)\n",
    "\n",
    "        for iter in range(config.iteration):\n",
    "            # run forward and backward propagation and update parameters\n",
    "            _, loss_cur, summary = sess.run([train_op, loss, merged],\n",
    "                                  feed_dict={batch: random_batch(), lr: config.lr*lr_factor})\n",
    "\n",
    "            loss_acc += loss_cur    # accumulated loss for each 100 iteration\n",
    "\n",
    "            if iter % 2 == 0:\n",
    "                writer.add_summary(summary, iter)   # write at tensorboard\n",
    "            if (iter+1) % 2 == 0:\n",
    "                logging.info(\"(epoch : %d) (iter : %d) loss: %.4f\" % (GlobalVar.epoch, (iter+1),loss_acc/2))\n",
    "                loss_acc = 0                        # reset accumulated loss\n",
    "            if (iter+1) % 5000 == 0: # decay at 10k\n",
    "                if config.lr*(lr_factor / 2) < 1e-4:\n",
    "                    logging.info(\"learning rate not decaying : \" + str(config.lr*lr_factor))\n",
    "                else:\n",
    "                    lr_factor /= 2                      # lr decay\n",
    "                    logging.info(\"learning rate is decayed! current lr : \" + str(config.lr*lr_factor))\n",
    "            if (iter+1) % 100 == 0:\n",
    "                saver.save(sess, os.path.join(path, \"Check_Point/model.ckpt\"), global_step=iter//100)\n",
    "                logging.info(\"model is saved!\")\n",
    "    logging.info(f'Training ended at: {str(datetime.utcnow().isoformat()[:-3])}')\n",
    "except Exception as e:\n",
    "    logging.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
