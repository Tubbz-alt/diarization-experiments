{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(M=5, N=4, beta1=0.5, beta2=0.9, comment='', hidden=768, hop=0.01, iteration=100000, loss='softmax', lr=0.01, model_num=6, model_path='./tisv_model', nfft=512, noise_filenum=16, noise_path='/datadrive2/dalon/diarization-experiments/Speaker_Verification/data/VCTK-Corpus/noise', num_layer=3, optim='sgd', proj=256, restore=False, sr=8000, tdsv=False, tdsv_frame=80, test_path='/datadrive2/dalon/diarization-experiments/Speaker_Verification/data/VCTK-Corpus/test', tisv_frame=50, train=False, train_path='/datadrive2/dalon/diarization-experiments/Speaker_Verification/data/VCTK-Corpus/train', window=0.025)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, logging, pickle\n",
    "import time\n",
    "from utils import random_batch, normalize, similarity, loss_cal, optim\n",
    "from configuration import get_config\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly in dev set:\n",
    "\n",
    "Voxceleb 2</br >\n",
    "Number of speakers = 5,994\n",
    "\n",
    "Voxceleb 1</br >\n",
    "Number of speakers = 1,211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voxceleb-1 structure\n",
    "# [['/datadrive2/dalon/diarization-experiments/voxceleb-dataset/voxceleb-1/wav/id10266/SHI6yGzrwLg/00001.wav',\n",
    "#   '/datadrive2/dalon/diarization-experiments/voxceleb-dataset/voxceleb-1/cleaned-data/id10266/SHI6yGzrwLg/00001.npy',\n",
    "#   (12, 40, 50)],\n",
    "# voxceleb1_file_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Voxceleb1 distribution\n",
    "# voxceleb1_file_path = \"/datadrive2/dalon/diarization-experiments/voxceleb-dataset/voxceleb-1/voxceleb-1.b\"\n",
    "# voxceleb1_file_list = np.load(voxceleb1_file_path)\n",
    "# voxceleb1_clean_list = [[x[1], int(x[2][0])] for x in voxceleb1_file_list if x[2][0] != 0]\n",
    "# voxceleb1_size_list = np.array([x[1] for x in voxceleb1_clean_list])\n",
    "# print(f'Total # of Utterances = {len(voxceleb1_size_list)}')\n",
    "# print(f'Max = {voxceleb1_size_list.max()}\\nMin = {voxceleb1_size_list.min()}\\nMean = {voxceleb1_size_list.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Voxceleb2 distribution\n",
    "# voxceleb2_file_path = \"/datadrive2/dalon/diarization-experiments/voxceleb-dataset/voxceleb-2/dev/voxceleb-2.b\"\n",
    "# voxceleb2_file_list = np.load(voxceleb2_file_path)\n",
    "# voxceleb2_clean_list = [[x[1], int(x[2][0])] for x in voxceleb2_file_list if x[2][0] != 0]\n",
    "# voxceleb2_size_list = np.array([x[1] for x in voxceleb2_clean_list])\n",
    "# print(f'Total # of Utterances = {len(voxceleb2_size_list)}')\n",
    "# print(f'Max = {voxceleb2_size_list.max()}\\nMin = {voxceleb2_size_list.min()}\\nMean = {voxceleb2_size_list.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path: /datadrive2/dalon/diarization-experiments/Speaker_Verification/Notebooks/voxceleb-2-train-v1.logs\n"
     ]
    }
   ],
   "source": [
    "# Voxceleb1 distribution cleanup\n",
    "dataset_name = 'voxceleb-2-train-v1'\n",
    "voxceleb_file_path = \"/datadrive2/dalon/diarization-experiments/voxceleb-dataset/voxceleb-2/dev/voxceleb-2.b\"\n",
    "save_dir = \"/datadrive2/dalon/diarization-experiments/voxceleb-dataset/voxceleb-2/train-data-v1\"\n",
    "log_file = os.path.abspath(dataset_name + \".logs\")\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\"\n",
    "    )\n",
    "print(f'Log path: {log_file}')\n",
    "\n",
    "\n",
    "voxceleb_file_list = np.load(voxceleb_file_path)\n",
    "voxceleb_map_speaker = [[x[1].split('/')[-3], x[1]] for x in voxceleb_file_list if x[2][0] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Saving directory: {save_dir}')\n",
    "voxceleb_map_speaker = defaultdict(list)\n",
    "for x in voxceleb_file_list:\n",
    "    if x[2][0] != 0:\n",
    "        voxceleb_map_speaker[x[1].split('/')[-3]].append(x[1])\n",
    "\n",
    "number_of_speakers = len(voxceleb_map_speaker)\n",
    "logging.info(f'Number of Speakers: {number_of_speakers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    allfiles = []\n",
    "    for idx, speakerid in enumerate(voxceleb_map_speaker):\n",
    "        logging.info(f'Processing: {idx + 1}/{number_of_speakers}')\n",
    "        save_path = os.path.join(save_dir, speakerid + \".npy\")\n",
    "        utterances = []\n",
    "        for files in voxceleb_map_speaker[speakerid]:\n",
    "            vals = np.load(files)\n",
    "            utterances.extend(vals.tolist())\n",
    "        utterances = np.array(utterances)\n",
    "        logging.info(f'Saving: {save_path}')\n",
    "        logging.info(utterances.shape)\n",
    "        np.save(save_path, utterances)\n",
    "        allfiles.append([save_path, utterances.shape])\n",
    "\n",
    "    logging.info(\"Completed!\")    \n",
    "except Exception as e:\n",
    "    logging.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, dataset_name + '.b'), \"wb\") as f:\n",
    "    # save the distribution\n",
    "    logging.info(f'Saving processed audio list to {os.path.join(save_dir, dataset_name + \".b\")}')\n",
    "    pickle.dump(allfiles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
