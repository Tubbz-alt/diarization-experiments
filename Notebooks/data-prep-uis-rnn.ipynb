{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps in data preparation\n",
    "\n",
    "1. Load the audio using librosa\n",
    "2. Get the duration using librosa.get_duration\n",
    "3. Calculate each frame width in ms\n",
    "4. Split the audio on VAD (Below 20db is silence)\n",
    "5. For each split calculate mel (180 frames) \n",
    "6. np.transpose the data Ex: (1,40,180) to (180,1,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path: /datadrive/dalon/diarization-experiments/Notebooks/data-generation-for-uisrnn.logs\n"
     ]
    }
   ],
   "source": [
    "# All imports\n",
    "import os, sys, logging\n",
    "import datetime\n",
    "import time, shutil, pickle\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pysrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import subprocess\n",
    "\n",
    "from utils import normalize, loss_cal, optim\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from configuration import get_config\n",
    "\n",
    "config = get_config()\n",
    "log_file = os.path.abspath(\"data-generation-for-uisrnn.logs\")\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\"\n",
    "    )\n",
    "print(f'Log path: {log_file}')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All configurations below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 222 # random seed\n",
    "config.N = 64 # Number of speakers per batch\n",
    "config.M = 10 # Number of utterences per speaker\n",
    "config.iteration = 50000000 # Number of iterations to run\n",
    "config.lr = 1e-3\n",
    "config.hidden = 768 # hidden state dimension of lstm\n",
    "config.proj = 256 # projection dimension of lstm\n",
    "# config.restore = True\n",
    "config.model_num = 46\n",
    "logging.info(f'N={config.N}, M={config.M}')\n",
    "logging.info(f'Model restore: {config.restore}, Model number: {config.model_num}')\n",
    "\n",
    "# Configurations\n",
    "\n",
    "#_____________ Parameters to tune on dev set _______________________\n",
    "# VAD param\n",
    "# Changing to 25, which will give slightly better intervals, 20 gives very short intervals\n",
    "vad_threshold = 25 # threshold for voice activity detection\n",
    "\n",
    "# Segment param\n",
    "acceptable_shortseg_dur = 0.2 # in second\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# model parameters\n",
    "model_path = '/datadrive/dalon/models/m-64-10-768-256/Check_Point/model.ckpt-46' # model save path\n",
    "dataset_path = '/datadrive/dalon/diarizer-dataset/VCTK-Corpus/wav48/'\n",
    "save_dir_path = '/datadrive/dalon/diarizer-dataset/VCTK-Corpus/embeddings'\n",
    "os.makedirs(save_dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm saving only 2 embeddings i.e. first and last tisv_frames for given interval in an audio. So each .npy\n",
    "embedding file will have a shape of (2, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /datadrive/dalon/diarization-experiments/Notebooks/utils.py:100: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "embedded size:  (2, 256)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 2 # Fixing to 2 since we take 2 for each interval #utter_batch.shape[1]\n",
    "verif = tf.placeholder(shape=[None, batch_size, 40], dtype=tf.float32)  # verification batch (time x batch x n_mel)\n",
    "batch = tf.concat([verif,], axis=1)\n",
    "\n",
    "# embedding lstm (3-layer default)\n",
    "with tf.variable_scope(\"lstm\"):\n",
    "    lstm_cells = [tf.contrib.rnn.LSTMCell(num_units=config.hidden, num_proj=config.proj) for i in range(config.num_layer)]\n",
    "    lstm = tf.contrib.rnn.MultiRNNCell(lstm_cells)    # make lstm op and variables\n",
    "    outputs, _ = tf.nn.dynamic_rnn(cell=lstm, inputs=batch, dtype=tf.float32, time_major=True)   # for TI-VS must use dynamic rnn\n",
    "    embedded = outputs[-1]                            # the last ouput is the embedded d-vector\n",
    "    embedded = normalize(embedded)                    # normalize\n",
    "\n",
    "print(\"embedded size: \", embedded.shape)\n",
    "\n",
    "config_tensorflow = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "saver = tf.train.Saver(var_list=tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /datadrive/dalon/models/m-64-10-768-256/Check_Point/model.ckpt-46\n"
     ]
    }
   ],
   "source": [
    "# Each embedding saved file will have (2, 256)\n",
    "with tf.Session(config=config_tensorflow) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "    for folder in os.listdir(dataset_path):\n",
    "        speakerid = folder\n",
    "        folder = os.path.join(dataset_path, folder)\n",
    "        for audio_file_name in os.listdir(folder):\n",
    "            audio_path = os.path.join(folder, audio_file_name)\n",
    "            audio_file_number = audio_file_name.split('.')[0].split('_')[1]\n",
    "            utter, sr = librosa.core.load(audio_path, sr=config.sr)        # load audio\n",
    "            utter_min_len = (config.tisv_frame * config.hop + config.window) * sr    # lower bound of utterance length\n",
    "            # Get the duration\n",
    "            duration = librosa.get_duration(utter, sr)\n",
    "            # Duration of each window\n",
    "            duration_per_frame = (duration / utter.shape[0])\n",
    "#             print(f'Duration: {duration}\\nDuration per frame: {duration_per_frame}s\\nMin length of utterance: {utter_min_len * duration_per_frame}s')\n",
    "            tisv_frame_duration_s = utter_min_len * duration_per_frame\n",
    "            intervals = librosa.effects.split(utter, top_db=vad_threshold)         # voice activity detection\n",
    "\n",
    "            for idx, current_interval in enumerate(intervals):\n",
    "                utterances_spec = []\n",
    "                utter_part = utter[current_interval[0]:current_interval[1]]         # save first and last 160 frames of spectrogram.\n",
    "                S = librosa.core.stft(y=utter_part, n_fft=config.nfft,\n",
    "                                      win_length=int(config.window * sr), hop_length=int(config.hop * sr))\n",
    "                S = np.abs(S) ** 2\n",
    "                mel_basis = librosa.filters.mel(sr=sr, n_fft=config.nfft, n_mels=40)\n",
    "                S = np.log10(np.dot(mel_basis, S) + 1e-6)           # log mel spectrogram of utterances\n",
    "        #         print(S.shape)\n",
    "                utterances_spec.append(S[:, :config.tisv_frame])\n",
    "                utterances_spec.append(S[:, -config.tisv_frame:])\n",
    "\n",
    "                utterances_spec = np.array(utterances_spec)\n",
    "                utter_batch = np.transpose(utterances_spec, axes=(2,0,1))     # transpose [frames, batch, n_mels]\n",
    "        #         print(utter_batch.shape)\n",
    "\n",
    "                data = sess.run(embedded, feed_dict={verif:utter_batch})\n",
    "                save_embedding_path = os.path.join(save_dir_path, f'vctk-{speakerid}-{audio_file_number}-{idx}.npy')\n",
    "                np.save(save_embedding_path, data)\n",
    "#                 print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## structuring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files 93417\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "list_of_embedding_path = sorted(os.listdir(save_dir_path))\n",
    "print(f'Total number of files {len(list_of_embedding_path)}')\n",
    "list_of_embedding_path[:5]\n",
    "\n",
    "embedding_dict = defaultdict(list)\n",
    "\n",
    "for file in list_of_embedding_path:\n",
    "    embedding_dict[file.split('-')[1]].append(os.path.join(save_dir_path, file))\n",
    "\n",
    "for key in embedding_dict:\n",
    "    if len(embedding_dict[key]) < 5: # remove the keys if its embeddings is less than 5\n",
    "        embedding_dict.pop(key)\n",
    "        print(f'Poped {key}')\n",
    "\n",
    "def shuffle_two(dict_of_two, train_sequence_path, train_ids):\n",
    "    \"\"\"Shuffle the given 2 labels\"\"\"\n",
    "    max_to_pick = 5\n",
    "    key1, key2 = dict_of_two.keys()\n",
    "#     print(len(dict_of_two[key1]), len(dict_of_two[key2]))\n",
    "    while dict_of_two[key1] and dict_of_two[key2]:\n",
    "#         print('in while')\n",
    "        no_to_pick = np.random.randint(1, max_to_pick)\n",
    "        if no_to_pick <= len(dict_of_two[key1]):\n",
    "#             print(no_to_pick, len(dict_of_two[key1]))\n",
    "            train_sequence_path.extend(dict_of_two[key1][:no_to_pick])\n",
    "            del dict_of_two[key1][:no_to_pick]\n",
    "            train_ids.extend([key1] * no_to_pick)\n",
    "        else: break\n",
    "        no_to_pick = np.random.randint(1, max_to_pick)\n",
    "        if no_to_pick <= len(dict_of_two[key2]):\n",
    "#             print(no_to_pick)\n",
    "            train_sequence_path.extend(dict_of_two[key2][:no_to_pick])\n",
    "            del dict_of_two[key2][:no_to_pick]\n",
    "            train_ids.extend([key2] * no_to_pick)\n",
    "        else: break\n",
    "    no_to_pick = len(dict_of_two[key1])\n",
    "    train_sequence_path.extend(dict_of_two[key1])\n",
    "    train_ids.extend([key1] * no_to_pick)\n",
    "    no_to_pick = len(dict_of_two[key2])\n",
    "    train_sequence_path.extend(dict_of_two[key2])\n",
    "    train_ids.extend([key2] * no_to_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 93417 93417\n"
     ]
    }
   ],
   "source": [
    "train_sequence_path = []\n",
    "train_ids = []\n",
    "while len(embedding_dict) >= 2:\n",
    "    first2pairs = {k: embedding_dict[k] for k in list(embedding_dict)[:2]}\n",
    "    shuffle_two(first2pairs, train_sequence_path, train_ids)\n",
    "    # remove the keys from embedding_dict\n",
    "    for key in first2pairs:\n",
    "        embedding_dict.pop(key)\n",
    "print(len(embedding_dict), len(train_sequence_path), len(train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sequence_path[81234:81239], train_ids[81234:81239]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = []\n",
    "train_cluster_id = []\n",
    "for idx, item in enumerate(train_sequence_path):\n",
    "    embeddings = np.load(item)\n",
    "    train_sequence.extend(embeddings.tolist())\n",
    "    train_cluster_id.extend([train_ids[idx], train_ids[idx]])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186834, 186834)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequence), len(train_cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/datadrive/dalon/diarizer-dataset/VCTK-Corpus/vctk_training_data.npz',\n",
    "         train_sequence=train_sequence, train_cluster_id=train_cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required datastructure for UIS-RNN training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.load('/datadrive/dalon/diarizer-dataset/VCTK-Corpus/vctk_training_data.npz') #'/datadrive/dalon/uis-rnn/data/training_data.npz')\n",
    "train_data = np.load('/datadrive/dalon/uis-rnn/data/training_data.npz')\n",
    "test_data = np.load('/datadrive/dalon/uis-rnn/data/testing_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.lib.npyio.NpzFile"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_sequence', 'train_cluster_id']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequence <class 'numpy.ndarray'>\n",
      "train_cluster_id <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for keys in train_data:\n",
    "    print(keys, type(train_data[keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = train_data['train_sequence']\n",
    "train_cluster_id = train_data['train_cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequence[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_0', '0_0', '0_0', '0_0', '0_0'], dtype='<U5')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cluster_id[20:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### datastructure\n",
    "data = {'train_sequence': ndarray of embeddings,\n",
    "        'train_cluster_id': ndarray of labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = np.load(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_sequences', 'test_cluster_ids']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for (test_sequence, test_cluster_id) in zip(test_data['test_sequences'], test_data['test_cluster_ids']):\n",
    "    print(not isinstance(test_sequence, np.ndarray))\n",
    "    print(test_sequence.dtype != float)\n",
    "    print((not isinstance(test_sequence, np.ndarray) or\n",
    "        test_sequence.dtype != float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequence.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_cluster_ids is an array of list, this list consists of lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sequences is an array of array, second array consis of audio embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09571809014298133"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['test_sequences'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005444454"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['test_sequences'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 125 125 125 42 125 125 66\n"
     ]
    }
   ],
   "source": [
    "print(*map(len, test_data['test_cluster_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoid = 'zPFptdATk_s'\n",
    "save_utter_label_interval = f'/datadrive/dalon/uis-rnn/Notebooks/{videoid}_5min.b'\n",
    "save_test_data = f'/datadrive/dalon/uis-rnn/Notebooks/{videoid}_test.npz' # it will have embeddings and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_utter_label_interval, 'rb') as f:\n",
    "    _tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /datadrive/dalon/models/m-64-10-768-256/Check_Point/model.ckpt-46\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "# Each embedding saved file will have (2, 256)\n",
    "with tf.Session(config=config_tensorflow) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.restore(sess, model_path)\n",
    "\n",
    "    utter = _tmp['utter']\n",
    "    sr = config.sr\n",
    "    utter_min_len = (config.tisv_frame * config.hop + config.window) * sr    # lower bound of utterance length\n",
    "    # Get the duration\n",
    "    duration = librosa.get_duration(utter, sr)\n",
    "    # Duration of each window\n",
    "    duration_per_frame = (duration / utter.shape[0])\n",
    "#             print(f'Duration: {duration}\\nDuration per frame: {duration_per_frame}s\\nMin length of utterance: {utter_min_len * duration_per_frame}s')\n",
    "    tisv_frame_duration_s = utter_min_len * duration_per_frame\n",
    "    intervals = _tmp['intervals']\n",
    "\n",
    "    for idx, current_interval in enumerate(intervals):\n",
    "        utterances_spec = []\n",
    "        utter_part = utter[current_interval[0]:current_interval[1]]         # save first and last 160 frames of spectrogram.\n",
    "        S = librosa.core.stft(y=utter_part, n_fft=config.nfft,\n",
    "                              win_length=int(config.window * sr), hop_length=int(config.hop * sr))\n",
    "        S = np.abs(S) ** 2\n",
    "        mel_basis = librosa.filters.mel(sr=sr, n_fft=config.nfft, n_mels=40)\n",
    "        S = np.log10(np.dot(mel_basis, S) + 1e-6)           # log mel spectrogram of utterances\n",
    "#         print(S.shape)\n",
    "        utterances_spec.append(S[:, :config.tisv_frame])\n",
    "        utterances_spec.append(S[:, -config.tisv_frame:])\n",
    "\n",
    "        utterances_spec = np.array(utterances_spec)\n",
    "        utter_batch = np.transpose(utterances_spec, axes=(2,0,1))     # transpose [frames, batch, n_mels]\n",
    "        data = sess.run(embedded, feed_dict={verif:utter_batch})\n",
    "        embeddings.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542, 256)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.array(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster_ids = []\n",
    "for item in _tmp['labels_list']:\n",
    "    test_cluster_ids.extend([item, item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(save_test_data,\n",
    "         test_sequences=embeddings,\n",
    "         test_cluster_ids=test_cluster_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create single npz file for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoids = ['zPFptdATk_s', 'VqF96Um0HQw']\n",
    "save_test_files = []\n",
    "for videoid in videoids:\n",
    "    save_test_files.append(f'/datadrive/dalon/uis-rnn/Notebooks/{videoid}_test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = []\n",
    "test_cluster_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512//125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert these into smaller chunks\n",
    "def split_to_chunks(test_sequences, test_cluster_ids, ids, seqs):\n",
    "    max_size = 125\n",
    "    start = 0\n",
    "    for i in range(len(ids) // max_size):\n",
    "        test_sequences.append(seqs[start:max_size * (i + 1)])\n",
    "        test_cluster_ids.append(ids[start:max_size * (i + 1)])\n",
    "        start = max_size * (i + 1)\n",
    "    test_sequences.append(seqs[start:])\n",
    "    test_cluster_ids.append(ids[start:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in save_test_files:\n",
    "    _tmp = np.load(file)\n",
    "    if len(list(_tmp['test_cluster_ids'])) > 150:\n",
    "        split_to_chunks(test_sequences,\n",
    "                        test_cluster_ids,\n",
    "                        list(_tmp['test_cluster_ids']),\n",
    "                        np.float64(_tmp['test_sequences']))\n",
    "    else:\n",
    "        test_sequences.append(np.float64(_tmp['test_sequences']))\n",
    "        test_cluster_ids.append(list(_tmp['test_cluster_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = np.array(test_sequences)\n",
    "test_cluster_ids = np.array(test_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = '/datadrive/dalon/uis-rnn/data/testing_data_custom_2vid.npz'\n",
    "np.savez(test_data_path,\n",
    "         test_sequences=test_sequences,\n",
    "         test_cluster_ids=test_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VCTK data prep for UIS-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path to vctk dataset\n",
    "# There are sub folders for each speaker with wav file inside them\n",
    "dataset_path = '/datadrive/dalon/diarizer-dataset/VCTK-Corpus/wav48/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_desc = defaultdict(list) # speaker id is the key and value is list of utterences\n",
    "for folder in os.listdir(dataset_path):\n",
    "    speakerid = folder\n",
    "    folder = os.path.join(dataset_path, folder)\n",
    "    for utter_path in os.listdir(folder):\n",
    "        utter_path = os.path.join(folder, utter_path)\n",
    "        speakers_desc[f'vctk-{speakerid}'].append(utter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_desc = []\n",
    "for key in speakers_desc:\n",
    "#     print(f'{key} = {len(speakers_desc[key])}')\n",
    "    utter_desc.append(len(speakers_desc[key]))\n",
    "utter_desc = np.array(utter_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 503, 405.89908256880733)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_desc.min(), utter_desc.max(), utter_desc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/datadrive/dalon/diarizer-dataset/VCTK-Corpus/vctk_training_data.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_sequence', 'train_cluster_id']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186834,)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_cluster_id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cossine similarity\n",
    "similarity = np.dot(data, data.T)\n",
    "\n",
    "# squared magnitude of preference vectors (number of occurrences) (diagonals are ai*ai)\n",
    "square_mag = np.diag(similarity)\n",
    "\n",
    "# inverse squared magnitude\n",
    "inv_square_mag = 1 / square_mag\n",
    "\n",
    "# if it doesn't occur, set it's inverse magnitude to zero (instead of inf)\n",
    "inv_square_mag[np.isinf(inv_square_mag)] = 0\n",
    "\n",
    "# inverse of the magnitude\n",
    "inv_mag = np.sqrt(inv_square_mag)\n",
    "\n",
    "# cosine similarity (elementwise multiply by inverse magnitudes)\n",
    "cosine = similarity * inv_mag\n",
    "A =  cosine.T * inv_mag\n",
    "\n",
    "# Fill the diagonals with very large negative value\n",
    "np.fill_diagonal(A, -1000)\n",
    "# Fill the diagonals with the max of each row\n",
    "np.fill_diagonal(A, A.max(axis=1))\n",
    "\n",
    "# final step in cossine sim\n",
    "A = (1-A)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Eigen vectors to pick: 4\n"
     ]
    }
   ],
   "source": [
    "# Gaussian blur\n",
    "sigma = 0.5 # we will select sigma as 0.5\n",
    "A_gau = gaussian_filter(A, sigma)\n",
    "\n",
    "# Thresholding using multiplier = 0.01\n",
    "threshold_multiplier = 0.01\n",
    "A_thresh = A_gau * threshold_multiplier\n",
    "\n",
    "# Symmetrization\n",
    "A_sym = np.maximum(A_thresh, A_thresh.T)\n",
    "\n",
    "# Diffusion\n",
    "A_diffusion = A_sym * A_sym.T\n",
    "\n",
    "# Row-wise matrix Normalization\n",
    "Row_max = A_diffusion.max(axis=1).reshape(1, A_diffusion.shape[0])\n",
    "A_norm = A_diffusion / Row_max.T\n",
    "\n",
    "# Eigen decomposition\n",
    "eigval, eigvec = np.linalg.eig(A_norm)\n",
    "# Since eigen values cannot be negative for Positive semi definite matrix, the numpy returns negative values, converting it to positive\n",
    "eigval = np.abs(eigval)\n",
    "# reordering eigen values\n",
    "sorted_eigval_idx = np.argsort(eigval)[::-1]\n",
    "sorted_eigval = np.sort(eigval)[::-1]\n",
    "\n",
    "# For division according to the equation\n",
    "eigval_shifted = np.roll(sorted_eigval, -1)\n",
    "# Thresholding eigen values because we don't need very low eigan values due to errors\n",
    "eigval_thresh = 0.1\n",
    "sorted_eigval = sorted_eigval[sorted_eigval > eigval_thresh]\n",
    "eigval_shifted = eigval_shifted[:sorted_eigval.shape[0]]\n",
    "\n",
    "# Don't take the first value for calculations, if first value is large, following equation will return k=1, and we want more than one clusters\n",
    "# Get the argmax of the division, since its 0 indexed, add 1\n",
    "k = np.argmax(sorted_eigval[1:]/eigval_shifted[1:]) + 2\n",
    "print(f'Number of Eigen vectors to pick: {k}')\n",
    "\n",
    "# Get the indexes of eigen vectors\n",
    "idexes = sorted_eigval_idx[:k]\n",
    "A_eigvec = eigvec[:, idexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(embeddings_path, A_eigvec, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means offline clustering\n",
    "Like in many diarization systems, we integrated the K-Means clustering algorithm with our system. Specifically, we use K-Means++ for initialization. To determine the number of speakers $k$,  we  use  the  “elbow”  of  the  derivatives  of  conditional  Mean Squared Cosine Distances 1 (MSCD) between each embedding to its cluster centroid: <br>\n",
    "$k = arg max_{\\substack{k \\geq 1}} MSCD(k)$ <br>\n",
    "We define cosine distance as $d(x, y) =(1−cos(x, y))/2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize as sk_normalize\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters = 2\n",
    "\n",
    "A_eigvec_norm = sk_normalize(A_eigvec) # l2 normalized\n",
    "kmeans = KMeans(n_clusters=number_of_clusters, init='k-means++', random_state=random_state)\n",
    "kmeans.fit(A_eigvec)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add speakers to the srt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(intervals_gt_s), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, c in enumerate(labels):\n",
    "#     print(f'{datetime.timedelta(seconds=intervals_gt_s[index][0])}=={datetime.timedelta(seconds=intervals_gt_s[index][1])}->{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervals_gt_s.index([635, 636])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadrive/dalon/diarizer-dataset/srts/outputs/Co4FdrBZgQs--160-0.025-0.01-20-0.2.en.srt\n"
     ]
    }
   ],
   "source": [
    "subs = pysrt.open(srt_path, encoding=\"utf-8\")\n",
    "convert_to_s = lambda st: (st.hours * 60 * 60) + \\\n",
    "                            (st.minutes * 60) +\\\n",
    "                            (st.seconds) #+ \\\n",
    "                            #(st.milliseconds / 1000)\n",
    "get_start_and_end = lambda sub: (convert_to_s(sub.start), convert_to_s(sub.end))\n",
    "\n",
    "for sub in subs:\n",
    "    start, end = get_start_and_end(sub)\n",
    "    speakers = []\n",
    "#     speakers_intervals = []\n",
    "    for idx, interval in enumerate(intervals_gt_s):\n",
    "#         interval[0], interval[1] = int(interval[0]), int(interval[1])\n",
    "        if interval[0] <= start <= interval[1] or interval[0] <= end <= interval[1]\\\n",
    "                or (start <= interval[0] and interval[1] <= end):\n",
    "            speakers.append(labels[idx])\n",
    "            if idx < len(intervals_gt_s) - 1 and intervals_gt_s[idx + 1][0] - interval[1] >= tisv_frame_duration_s:\n",
    "                speakers.append(-1)\n",
    "\n",
    "#________________debug________________\n",
    "#     if sub.index == 171:\n",
    "#         for idx, interval in enumerate(intervals_gt_s):\n",
    "#             if interval[0] <= start <= interval[1] or interval[0] <= end <= interval[1]: \n",
    "#                 print(interval)\n",
    "#         print(f'{start, end}')\n",
    "#         print(f'here: {speakers} T:{end - start} {sub.text}')\n",
    "#         break\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "            \n",
    "    if speakers:\n",
    "#         print(speakers)\n",
    "        sp_list, sp_count = np.unique(speakers, return_counts=True)\n",
    "        speaker_dist = 'Speakers: '\n",
    "        number_speakers = len(speakers)\n",
    "        for idx, sp in enumerate(sp_list):\n",
    "            speaker_dist += f'{sp}, '\n",
    "        sub.text = f'{speaker_dist[:-2]} S:{speakers} T:{end - start} {sub.text}'\n",
    "subs.save(save_srt_path, encoding='utf-8')\n",
    "print(save_srt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start <= 635 and 636 <= end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 635 <= end <= 636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval[0], interval[1],start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speakers = []\n",
    "# for idx, interval in enumerate(intervsals_gt_s):\n",
    "#     if interval[0] <= start <= interval[1] or interval[0] <= end <= interval[1]:\n",
    "#         speakers.append(labels[idx])\n",
    "#     if idx == 120: break\n",
    "#     print(speakers, interval[0], interval[1],start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i,sub in enumerate(subs):\n",
    "#     if not sub.text.startswith(\"Speakers\"):\n",
    "#         print(sub.index)\n",
    "#         count += 1\n",
    "# print(count, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
